{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment 4 - Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURE18/Practical-Machine-Learning-with-Tensorflow/blob/master/Copy_of_Assignment_4_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLVhCarMwG70",
        "colab_type": "text"
      },
      "source": [
        "### **Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teXJ1XpSwdvR",
        "colab_type": "text"
      },
      "source": [
        "Install and import all the necessary libraries for the assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQNMrFD-ZBwK",
        "colab_type": "code",
        "outputId": "c4b8adb3-faff-48d4-d3b9-b03f2a6b8567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0-rc0\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_boston\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "tf.random.set_seed(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2.0.0-rc0 in /usr/local/lib/python3.6/dist-packages (2.0.0rc0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.16.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (3.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.12.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.14.0.dev2019080601)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.33.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: tb-nightly<1.15.0a20190807,>=1.15.0a20190806 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.15.0a20190806)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.1.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-rc0) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-rc0) (41.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0-rc0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0) (0.15.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow==2.0.0-rc0) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGGgAUOKwsWA",
        "colab_type": "text"
      },
      "source": [
        "### **Importing the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOe2azQOdmND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boston_dataset = load_boston()\n",
        "\n",
        "data_X = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
        "data_Y = pd.DataFrame(boston_dataset.target, columns=[\"target\"])\n",
        "data = pd.concat([data_X, data_Y], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gD5esSxfxjs",
        "colab_type": "code",
        "outputId": "bdeac6f7-6e43-4282-89d0-62e6269a5c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train, test = train_test_split(data, test_size=0.2, random_state=1)\n",
        "train, val = train_test_split(train, test_size=0.2, random_state=1)\n",
        "print(len(train), \"train examples\")\n",
        "print(len(val), \"validation examples\")\n",
        "print(len(test), \"test examples\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "323 train examples\n",
            "81 validation examples\n",
            "102 test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoeE59_aRVHI",
        "colab_type": "code",
        "outputId": "d80b56cb-5025-4193-b5cf-dd2c8c4e7a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        }
      },
      "source": [
        "train.describe().T"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CRIM</th>\n",
              "      <td>323.0</td>\n",
              "      <td>3.882044</td>\n",
              "      <td>9.680410</td>\n",
              "      <td>0.00632</td>\n",
              "      <td>0.082865</td>\n",
              "      <td>0.25387</td>\n",
              "      <td>3.944055</td>\n",
              "      <td>88.9762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ZN</th>\n",
              "      <td>323.0</td>\n",
              "      <td>12.233746</td>\n",
              "      <td>24.323780</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>100.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INDUS</th>\n",
              "      <td>323.0</td>\n",
              "      <td>11.121796</td>\n",
              "      <td>6.876617</td>\n",
              "      <td>0.46000</td>\n",
              "      <td>5.190000</td>\n",
              "      <td>8.56000</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>27.7400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAS</th>\n",
              "      <td>323.0</td>\n",
              "      <td>0.080495</td>\n",
              "      <td>0.272481</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NOX</th>\n",
              "      <td>323.0</td>\n",
              "      <td>0.553683</td>\n",
              "      <td>0.118625</td>\n",
              "      <td>0.38500</td>\n",
              "      <td>0.447500</td>\n",
              "      <td>0.53200</td>\n",
              "      <td>0.624000</td>\n",
              "      <td>0.8710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RM</th>\n",
              "      <td>323.0</td>\n",
              "      <td>6.276935</td>\n",
              "      <td>0.691051</td>\n",
              "      <td>3.56100</td>\n",
              "      <td>5.886500</td>\n",
              "      <td>6.19300</td>\n",
              "      <td>6.666500</td>\n",
              "      <td>8.7800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGE</th>\n",
              "      <td>323.0</td>\n",
              "      <td>68.279876</td>\n",
              "      <td>28.452257</td>\n",
              "      <td>2.90000</td>\n",
              "      <td>43.550000</td>\n",
              "      <td>77.70000</td>\n",
              "      <td>93.900000</td>\n",
              "      <td>100.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIS</th>\n",
              "      <td>323.0</td>\n",
              "      <td>3.864749</td>\n",
              "      <td>2.154972</td>\n",
              "      <td>1.12960</td>\n",
              "      <td>2.120350</td>\n",
              "      <td>3.36030</td>\n",
              "      <td>5.237900</td>\n",
              "      <td>12.1265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAD</th>\n",
              "      <td>323.0</td>\n",
              "      <td>9.721362</td>\n",
              "      <td>8.801984</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.00000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>24.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TAX</th>\n",
              "      <td>323.0</td>\n",
              "      <td>406.588235</td>\n",
              "      <td>170.365557</td>\n",
              "      <td>187.00000</td>\n",
              "      <td>279.000000</td>\n",
              "      <td>329.00000</td>\n",
              "      <td>666.000000</td>\n",
              "      <td>711.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PTRATIO</th>\n",
              "      <td>323.0</td>\n",
              "      <td>18.483282</td>\n",
              "      <td>2.162864</td>\n",
              "      <td>12.60000</td>\n",
              "      <td>17.350000</td>\n",
              "      <td>19.10000</td>\n",
              "      <td>20.200000</td>\n",
              "      <td>22.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>323.0</td>\n",
              "      <td>359.145604</td>\n",
              "      <td>89.252050</td>\n",
              "      <td>0.32000</td>\n",
              "      <td>376.355000</td>\n",
              "      <td>391.93000</td>\n",
              "      <td>396.100000</td>\n",
              "      <td>396.9000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTAT</th>\n",
              "      <td>323.0</td>\n",
              "      <td>12.733529</td>\n",
              "      <td>7.251569</td>\n",
              "      <td>1.73000</td>\n",
              "      <td>7.065000</td>\n",
              "      <td>11.45000</td>\n",
              "      <td>17.155000</td>\n",
              "      <td>37.9700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>323.0</td>\n",
              "      <td>22.674613</td>\n",
              "      <td>9.028215</td>\n",
              "      <td>5.00000</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>21.20000</td>\n",
              "      <td>26.400000</td>\n",
              "      <td>50.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         count        mean         std  ...        50%         75%       max\n",
              "CRIM     323.0    3.882044    9.680410  ...    0.25387    3.944055   88.9762\n",
              "ZN       323.0   12.233746   24.323780  ...    0.00000   19.000000  100.0000\n",
              "INDUS    323.0   11.121796    6.876617  ...    8.56000   18.100000   27.7400\n",
              "CHAS     323.0    0.080495    0.272481  ...    0.00000    0.000000    1.0000\n",
              "NOX      323.0    0.553683    0.118625  ...    0.53200    0.624000    0.8710\n",
              "RM       323.0    6.276935    0.691051  ...    6.19300    6.666500    8.7800\n",
              "AGE      323.0   68.279876   28.452257  ...   77.70000   93.900000  100.0000\n",
              "DIS      323.0    3.864749    2.154972  ...    3.36030    5.237900   12.1265\n",
              "RAD      323.0    9.721362    8.801984  ...    5.00000   24.000000   24.0000\n",
              "TAX      323.0  406.588235  170.365557  ...  329.00000  666.000000  711.0000\n",
              "PTRATIO  323.0   18.483282    2.162864  ...   19.10000   20.200000   22.0000\n",
              "B        323.0  359.145604   89.252050  ...  391.93000  396.100000  396.9000\n",
              "LSTAT    323.0   12.733529    7.251569  ...   11.45000   17.155000   37.9700\n",
              "target   323.0   22.674613    9.028215  ...   21.20000   26.400000   50.0000\n",
              "\n",
              "[14 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZTeC55HxDeT",
        "colab_type": "text"
      },
      "source": [
        "Converting the Pandas DataFrames into Tensorflow Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF4GRPPLdTIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('target')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdZy7p3AaTRT",
        "colab_type": "code",
        "outputId": "ff2aad0c-b42f-4b95-8ba2-c96237ad99b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "batch_size = 32\n",
        "train_ds = df_to_dataset(train, True, batch_size)\n",
        "val_ds = df_to_dataset(val, False, batch_size)\n",
        "test_ds = df_to_dataset(test, False, batch_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0IM1Y_KuG4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBQ1OiDllbr9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WjCCT0BQWpq",
        "colab_type": "code",
        "outputId": "41c6348f-87f4-413b-ad22-a4e2c3bee984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
              "       'PTRATIO', 'B', 'LSTAT', 'target'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63KuTr4sxMl6",
        "colab_type": "text"
      },
      "source": [
        "### Defining Feature Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "380jHjPokFUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define feature_columns as a list of features using functions from tf.feature_column\n",
        "\n",
        "feature_columns = []\n",
        "for key in feature_batch.keys():\n",
        "    feature_columns.append(tf.feature_column.numeric_column(key))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXCxjTuqKTab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f6682f85-99d4-4f2c-9f40-9a8c4d4bb7db"
      },
      "source": [
        "feature_columns"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[NumericColumn(key='CRIM', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='ZN', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='INDUS', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='CHAS', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='NOX', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='RM', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='AGE', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='DIS', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='RAD', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='TAX', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='PTRATIO', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='B', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
              " NumericColumn(key='LSTAT', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykVCMrdMxVB5",
        "colab_type": "text"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAc9LpVzqql9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6B9FgRyyGXe",
        "colab_type": "text"
      },
      "source": [
        "Model should contain following layers:\n",
        "\n",
        "```\n",
        "feature_layer\n",
        "\n",
        "Dense(1, activation=None)\n",
        "```\n",
        "\n",
        "Use 'Adam' optimizer\n",
        "\n",
        "Use 'mse' as your loss and metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZInuZ8D0xsu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build and compile your model in this cell.\n",
        "model = tf.keras.Sequential([\n",
        "                             feature_layer,\n",
        "                             tf.keras.layers.Dense(1,activation=None)])\n",
        "model.compile(loss='mean_squared_error',optimizer='adam',metrics=['mean_squared_error'])\n",
        "\n",
        "# model.compile(optimizer='adam',loss='mean_squared_error',metrics='mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igdzl3wasRo6",
        "colab_type": "code",
        "outputId": "b7787450-77cd-407b-9b67-912f33251787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_ds, validation_data=val_ds, epochs=200)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer sequential_11 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "Epoch 1/200\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 26289.7013 - mean_squared_error: 24809.9785 - val_loss: 0.0000e+00 - val_mean_squared_error: 0.0000e+00\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 21972.5175 - mean_squared_error: 21943.3418 - val_loss: 17897.3880 - val_mean_squared_error: 18885.4219\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 19495.4565 - mean_squared_error: 19372.2832 - val_loss: 15756.3008 - val_mean_squared_error: 16681.2324\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 17215.6988 - mean_squared_error: 17081.3555 - val_loss: 13890.7305 - val_mean_squared_error: 14757.2842\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 14879.6305 - mean_squared_error: 15012.6084 - val_loss: 12274.1717 - val_mean_squared_error: 13086.3770\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 13184.0277 - mean_squared_error: 13189.8418 - val_loss: 10753.1232 - val_mean_squared_error: 11509.6309\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 11601.9379 - mean_squared_error: 11544.1758 - val_loss: 9428.3786 - val_mean_squared_error: 10132.7246\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 10130.6201 - mean_squared_error: 10121.8574 - val_loss: 8305.1486 - val_mean_squared_error: 8961.7373\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 8913.7844 - mean_squared_error: 8902.1846 - val_loss: 7319.8634 - val_mean_squared_error: 7930.4678\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 7898.7547 - mean_squared_error: 7833.4097 - val_loss: 6489.3625 - val_mean_squared_error: 7057.2739\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6917.7847 - mean_squared_error: 6913.0171 - val_loss: 5829.6134 - val_mean_squared_error: 6360.6650\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 6075.3483 - mean_squared_error: 6164.4990 - val_loss: 5232.7543 - val_mean_squared_error: 5726.6582\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 5485.0877 - mean_squared_error: 5491.3579 - val_loss: 4704.0844 - val_mean_squared_error: 5161.1309\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4952.5757 - mean_squared_error: 4917.1108 - val_loss: 4276.5770 - val_mean_squared_error: 4700.6943\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4427.8933 - mean_squared_error: 4447.3901 - val_loss: 3953.4642 - val_mean_squared_error: 4349.8291\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 4071.3880 - mean_squared_error: 4063.7090 - val_loss: 3668.6723 - val_mean_squared_error: 4037.8923\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3771.5951 - mean_squared_error: 3745.3203 - val_loss: 3438.6992 - val_mean_squared_error: 3783.3955\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3496.0654 - mean_squared_error: 3488.8936 - val_loss: 3265.0489 - val_mean_squared_error: 3589.2805\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3284.7084 - mean_squared_error: 3276.4109 - val_loss: 3115.3011 - val_mean_squared_error: 3420.1577\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 3126.7300 - mean_squared_error: 3106.3169 - val_loss: 2983.5867 - val_mean_squared_error: 3269.6582\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2961.4556 - mean_squared_error: 2951.7900 - val_loss: 2882.2777 - val_mean_squared_error: 3153.0122\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2846.0329 - mean_squared_error: 2826.3105 - val_loss: 2791.2717 - val_mean_squared_error: 3047.1516\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2724.6700 - mean_squared_error: 2716.4573 - val_loss: 2715.5198 - val_mean_squared_error: 2958.5586\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2642.9211 - mean_squared_error: 2627.4993 - val_loss: 2648.6404 - val_mean_squared_error: 2880.6641\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2560.0618 - mean_squared_error: 2548.6394 - val_loss: 2588.2102 - val_mean_squared_error: 2810.1318\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2432.1053 - mean_squared_error: 2478.6599 - val_loss: 2529.4549 - val_mean_squared_error: 2741.8132\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2418.0630 - mean_squared_error: 2402.9094 - val_loss: 2467.0089 - val_mean_squared_error: 2667.7886\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2346.6350 - mean_squared_error: 2336.6809 - val_loss: 2412.3599 - val_mean_squared_error: 2604.1240\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2288.0551 - mean_squared_error: 2273.9634 - val_loss: 2363.7266 - val_mean_squared_error: 2547.1897\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2226.3394 - mean_squared_error: 2218.3469 - val_loss: 2316.6984 - val_mean_squared_error: 2493.8000\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2169.5184 - mean_squared_error: 2166.1663 - val_loss: 2270.6696 - val_mean_squared_error: 2440.9250\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2111.6755 - mean_squared_error: 2114.9578 - val_loss: 2225.7623 - val_mean_squared_error: 2387.6636\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2075.2738 - mean_squared_error: 2063.5271 - val_loss: 2182.7323 - val_mean_squared_error: 2336.5535\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 2027.6957 - mean_squared_error: 2015.8572 - val_loss: 2137.5264 - val_mean_squared_error: 2286.7080\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1978.1090 - mean_squared_error: 1971.4601 - val_loss: 2093.0231 - val_mean_squared_error: 2238.5969\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1887.3286 - mean_squared_error: 1927.9387 - val_loss: 2047.4815 - val_mean_squared_error: 2189.5317\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1888.2427 - mean_squared_error: 1883.1707 - val_loss: 1996.6367 - val_mean_squared_error: 2133.4678\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1832.2332 - mean_squared_error: 1833.7999 - val_loss: 1954.8045 - val_mean_squared_error: 2085.8582\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1800.6294 - mean_squared_error: 1789.5999 - val_loss: 1912.5612 - val_mean_squared_error: 2038.1064\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1729.2337 - mean_squared_error: 1748.5917 - val_loss: 1869.7599 - val_mean_squared_error: 1990.9285\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1713.0008 - mean_squared_error: 1704.4214 - val_loss: 1826.1735 - val_mean_squared_error: 1942.9419\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1676.6877 - mean_squared_error: 1666.3597 - val_loss: 1782.2059 - val_mean_squared_error: 1895.3986\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1630.6277 - mean_squared_error: 1624.4133 - val_loss: 1739.7347 - val_mean_squared_error: 1850.6709\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1594.5795 - mean_squared_error: 1587.2157 - val_loss: 1696.9292 - val_mean_squared_error: 1805.9724\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1557.2075 - mean_squared_error: 1551.0814 - val_loss: 1657.2271 - val_mean_squared_error: 1763.0609\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1523.3297 - mean_squared_error: 1513.8763 - val_loss: 1618.8005 - val_mean_squared_error: 1721.7396\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1478.4834 - mean_squared_error: 1478.8958 - val_loss: 1580.8356 - val_mean_squared_error: 1681.1537\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1456.9890 - mean_squared_error: 1445.1578 - val_loss: 1542.5710 - val_mean_squared_error: 1641.3663\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1415.9634 - mean_squared_error: 1412.6567 - val_loss: 1507.3045 - val_mean_squared_error: 1603.2762\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1374.4516 - mean_squared_error: 1380.6615 - val_loss: 1473.1700 - val_mean_squared_error: 1565.1151\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1353.7319 - mean_squared_error: 1346.9513 - val_loss: 1436.2579 - val_mean_squared_error: 1525.3513\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 1320.4191 - mean_squared_error: 1313.6844 - val_loss: 1400.9339 - val_mean_squared_error: 1487.9384\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1288.2814 - mean_squared_error: 1282.6954 - val_loss: 1367.6512 - val_mean_squared_error: 1451.4335\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1259.1109 - mean_squared_error: 1252.1914 - val_loss: 1337.1180 - val_mean_squared_error: 1416.9733\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1215.2605 - mean_squared_error: 1221.7721 - val_loss: 1305.9683 - val_mean_squared_error: 1382.6836\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1198.9211 - mean_squared_error: 1191.4880 - val_loss: 1274.7530 - val_mean_squared_error: 1348.5886\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1168.9079 - mean_squared_error: 1162.9205 - val_loss: 1243.7006 - val_mean_squared_error: 1315.0348\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1138.3460 - mean_squared_error: 1135.3022 - val_loss: 1211.4030 - val_mean_squared_error: 1281.2729\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1111.5230 - mean_squared_error: 1107.0305 - val_loss: 1182.4008 - val_mean_squared_error: 1249.6923\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1084.2267 - mean_squared_error: 1081.3195 - val_loss: 1153.4697 - val_mean_squared_error: 1218.0869\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1059.2620 - mean_squared_error: 1054.3242 - val_loss: 1122.4073 - val_mean_squared_error: 1185.8875\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1035.6454 - mean_squared_error: 1030.6183 - val_loss: 1092.0051 - val_mean_squared_error: 1154.6073\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 1010.2351 - mean_squared_error: 1005.5477 - val_loss: 1065.1777 - val_mean_squared_error: 1125.5549\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 961.9081 - mean_squared_error: 980.5430 - val_loss: 1040.3183 - val_mean_squared_error: 1098.0947\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 962.0776 - mean_squared_error: 957.0831 - val_loss: 1013.3488 - val_mean_squared_error: 1067.4423\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 935.8549 - mean_squared_error: 930.8843 - val_loss: 988.1098 - val_mean_squared_error: 1040.0371\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 913.1739 - mean_squared_error: 908.7951 - val_loss: 963.6747 - val_mean_squared_error: 1013.6872\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 891.6054 - mean_squared_error: 887.4612 - val_loss: 937.9513 - val_mean_squared_error: 986.6276\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 867.7998 - mean_squared_error: 866.0234 - val_loss: 912.3450 - val_mean_squared_error: 960.0507\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 839.3847 - mean_squared_error: 845.1280 - val_loss: 887.0293 - val_mean_squared_error: 934.1296\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 829.5488 - mean_squared_error: 824.9640 - val_loss: 863.4240 - val_mean_squared_error: 908.5148\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 801.2411 - mean_squared_error: 805.3534 - val_loss: 842.5603 - val_mean_squared_error: 885.3502\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 781.9128 - mean_squared_error: 785.2842 - val_loss: 823.2334 - val_mean_squared_error: 863.8859\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 770.1712 - mean_squared_error: 767.0430 - val_loss: 800.6902 - val_mean_squared_error: 840.5164\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 753.4585 - mean_squared_error: 748.4361 - val_loss: 780.3488 - val_mean_squared_error: 819.4719\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 718.9886 - mean_squared_error: 731.8250 - val_loss: 759.6900 - val_mean_squared_error: 798.0253\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 715.5856 - mean_squared_error: 713.6450 - val_loss: 738.7123 - val_mean_squared_error: 775.2689\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 700.8227 - mean_squared_error: 697.3987 - val_loss: 721.2503 - val_mean_squared_error: 755.8467\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 670.1601 - mean_squared_error: 680.3616 - val_loss: 702.3656 - val_mean_squared_error: 736.0415\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 666.4524 - mean_squared_error: 665.0278 - val_loss: 682.4553 - val_mean_squared_error: 714.6313\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 650.6033 - mean_squared_error: 647.5483 - val_loss: 663.7923 - val_mean_squared_error: 695.3600\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 633.0774 - mean_squared_error: 633.8012 - val_loss: 648.0030 - val_mean_squared_error: 678.3356\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 621.6909 - mean_squared_error: 618.7627 - val_loss: 629.4963 - val_mean_squared_error: 659.8640\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 600.9035 - mean_squared_error: 605.5361 - val_loss: 612.4562 - val_mean_squared_error: 642.3016\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 596.0905 - mean_squared_error: 592.1893 - val_loss: 597.5504 - val_mean_squared_error: 626.0222\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 578.9584 - mean_squared_error: 578.7712 - val_loss: 583.7379 - val_mean_squared_error: 611.1516\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 569.8783 - mean_squared_error: 566.7764 - val_loss: 571.2313 - val_mean_squared_error: 597.1122\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 557.5611 - mean_squared_error: 554.5414 - val_loss: 556.9857 - val_mean_squared_error: 582.2457\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 544.8334 - mean_squared_error: 542.5029 - val_loss: 542.6673 - val_mean_squared_error: 567.7227\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 530.4246 - mean_squared_error: 531.4909 - val_loss: 528.1567 - val_mean_squared_error: 553.0059\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 524.6490 - mean_squared_error: 520.7673 - val_loss: 513.7538 - val_mean_squared_error: 538.6776\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 502.2502 - mean_squared_error: 510.3341 - val_loss: 501.5186 - val_mean_squared_error: 525.6890\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 490.6936 - mean_squared_error: 500.0238 - val_loss: 489.3584 - val_mean_squared_error: 513.1945\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 482.8905 - mean_squared_error: 488.7927 - val_loss: 477.7017 - val_mean_squared_error: 500.0499\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 473.4372 - mean_squared_error: 477.5371 - val_loss: 468.0175 - val_mean_squared_error: 488.8244\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 467.1898 - mean_squared_error: 467.9301 - val_loss: 457.5012 - val_mean_squared_error: 477.3385\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 461.0607 - mean_squared_error: 458.3632 - val_loss: 445.2215 - val_mean_squared_error: 464.9605\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 439.8058 - mean_squared_error: 448.6414 - val_loss: 434.0863 - val_mean_squared_error: 453.6152\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 441.4306 - mean_squared_error: 439.1714 - val_loss: 421.8242 - val_mean_squared_error: 440.8880\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 424.5390 - mean_squared_error: 429.5613 - val_loss: 410.5994 - val_mean_squared_error: 429.4994\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 422.9556 - mean_squared_error: 421.3091 - val_loss: 399.8913 - val_mean_squared_error: 417.9483\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 415.1977 - mean_squared_error: 411.7751 - val_loss: 389.7921 - val_mean_squared_error: 407.8447\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 403.2719 - mean_squared_error: 404.2165 - val_loss: 381.2058 - val_mean_squared_error: 398.8832\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 391.5255 - mean_squared_error: 396.9427 - val_loss: 372.8761 - val_mean_squared_error: 389.8366\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 389.3090 - mean_squared_error: 388.7473 - val_loss: 364.4601 - val_mean_squared_error: 380.6116\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 382.6904 - mean_squared_error: 381.4747 - val_loss: 354.7317 - val_mean_squared_error: 370.9953\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 366.4315 - mean_squared_error: 374.3613 - val_loss: 346.8816 - val_mean_squared_error: 362.9496\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 369.2576 - mean_squared_error: 367.6488 - val_loss: 339.0990 - val_mean_squared_error: 355.2205\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 359.5696 - mean_squared_error: 361.6487 - val_loss: 331.5431 - val_mean_squared_error: 347.7085\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 357.5572 - mean_squared_error: 355.9112 - val_loss: 325.3067 - val_mean_squared_error: 340.9810\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 350.8654 - mean_squared_error: 349.9120 - val_loss: 319.1677 - val_mean_squared_error: 334.4146\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 344.2973 - mean_squared_error: 343.8830 - val_loss: 311.6784 - val_mean_squared_error: 326.9720\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 339.6481 - mean_squared_error: 338.3014 - val_loss: 305.7691 - val_mean_squared_error: 320.8138\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 334.0736 - mean_squared_error: 333.1259 - val_loss: 299.0294 - val_mean_squared_error: 314.1310\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 330.0707 - mean_squared_error: 327.6664 - val_loss: 293.1932 - val_mean_squared_error: 308.3837\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 323.9382 - mean_squared_error: 323.0594 - val_loss: 287.5008 - val_mean_squared_error: 302.6725\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 310.8511 - mean_squared_error: 318.3498 - val_loss: 282.2922 - val_mean_squared_error: 297.0877\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 309.9469 - mean_squared_error: 313.2859 - val_loss: 275.9879 - val_mean_squared_error: 290.5431\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 307.4932 - mean_squared_error: 307.9766 - val_loss: 271.0150 - val_mean_squared_error: 285.1229\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 297.9889 - mean_squared_error: 303.0464 - val_loss: 266.0360 - val_mean_squared_error: 279.7423\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 296.7472 - mean_squared_error: 298.7929 - val_loss: 260.3848 - val_mean_squared_error: 273.8848\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 291.3547 - mean_squared_error: 293.4625 - val_loss: 253.7751 - val_mean_squared_error: 267.3690\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 290.3355 - mean_squared_error: 288.2269 - val_loss: 247.8152 - val_mean_squared_error: 261.6061\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 279.0869 - mean_squared_error: 284.2580 - val_loss: 242.5546 - val_mean_squared_error: 256.4052\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 280.9035 - mean_squared_error: 279.4232 - val_loss: 237.8047 - val_mean_squared_error: 251.2490\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 277.1507 - mean_squared_error: 275.9088 - val_loss: 233.7466 - val_mean_squared_error: 246.9980\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 273.0887 - mean_squared_error: 271.7317 - val_loss: 229.0327 - val_mean_squared_error: 242.4227\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 269.9740 - mean_squared_error: 268.4329 - val_loss: 224.5883 - val_mean_squared_error: 238.1573\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 265.8553 - mean_squared_error: 264.9478 - val_loss: 221.2135 - val_mean_squared_error: 234.6870\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 263.5250 - mean_squared_error: 262.1309 - val_loss: 217.9049 - val_mean_squared_error: 231.2939\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 260.6666 - mean_squared_error: 258.7956 - val_loss: 214.0690 - val_mean_squared_error: 227.6541\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 257.7402 - mean_squared_error: 255.6693 - val_loss: 210.7817 - val_mean_squared_error: 224.3572\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 254.7055 - mean_squared_error: 252.7653 - val_loss: 207.5985 - val_mean_squared_error: 221.1889\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 249.7877 - mean_squared_error: 249.9121 - val_loss: 204.5347 - val_mean_squared_error: 218.0574\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 243.4933 - mean_squared_error: 246.8830 - val_loss: 201.0985 - val_mean_squared_error: 214.5439\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 243.5402 - mean_squared_error: 243.7145 - val_loss: 198.2780 - val_mean_squared_error: 211.4873\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 241.1273 - mean_squared_error: 241.2251 - val_loss: 195.8368 - val_mean_squared_error: 208.8116\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 239.5920 - mean_squared_error: 238.3887 - val_loss: 191.8705 - val_mean_squared_error: 205.0519\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 228.8921 - mean_squared_error: 235.3519 - val_loss: 188.5442 - val_mean_squared_error: 201.8849\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 233.0808 - mean_squared_error: 232.6799 - val_loss: 185.3468 - val_mean_squared_error: 198.6604\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 230.2675 - mean_squared_error: 229.8886 - val_loss: 182.5768 - val_mean_squared_error: 196.0302\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 229.4521 - mean_squared_error: 228.0289 - val_loss: 179.8155 - val_mean_squared_error: 193.4539\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 214.6078 - mean_squared_error: 225.5896 - val_loss: 177.4840 - val_mean_squared_error: 191.0510\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 223.2513 - mean_squared_error: 223.3659 - val_loss: 175.5725 - val_mean_squared_error: 189.3898\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 222.0878 - mean_squared_error: 221.7117 - val_loss: 173.5602 - val_mean_squared_error: 187.4435\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 216.3399 - mean_squared_error: 218.9437 - val_loss: 171.0056 - val_mean_squared_error: 184.7157\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 217.8669 - mean_squared_error: 216.3189 - val_loss: 168.6546 - val_mean_squared_error: 182.0157\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 213.7495 - mean_squared_error: 213.9329 - val_loss: 166.7267 - val_mean_squared_error: 180.0185\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 213.6488 - mean_squared_error: 212.2109 - val_loss: 164.5817 - val_mean_squared_error: 177.8351\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 207.8068 - mean_squared_error: 210.1853 - val_loss: 162.3544 - val_mean_squared_error: 175.6605\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 208.1749 - mean_squared_error: 208.0313 - val_loss: 159.6827 - val_mean_squared_error: 173.1946\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 206.4038 - mean_squared_error: 205.8025 - val_loss: 157.7142 - val_mean_squared_error: 171.3046\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 203.4982 - mean_squared_error: 203.9031 - val_loss: 155.8480 - val_mean_squared_error: 169.5707\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 203.2412 - mean_squared_error: 202.3762 - val_loss: 154.0903 - val_mean_squared_error: 167.8184\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 201.2774 - mean_squared_error: 200.4314 - val_loss: 152.5415 - val_mean_squared_error: 166.2605\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 200.4157 - mean_squared_error: 199.1044 - val_loss: 151.1306 - val_mean_squared_error: 164.8200\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 197.7122 - mean_squared_error: 197.4405 - val_loss: 149.4138 - val_mean_squared_error: 163.1768\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 196.6574 - mean_squared_error: 195.9506 - val_loss: 148.1173 - val_mean_squared_error: 161.8376\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 192.8521 - mean_squared_error: 194.4445 - val_loss: 146.3864 - val_mean_squared_error: 160.1461\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 194.1652 - mean_squared_error: 192.8047 - val_loss: 144.5114 - val_mean_squared_error: 158.3665\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 191.4473 - mean_squared_error: 191.1116 - val_loss: 143.1619 - val_mean_squared_error: 157.0054\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 191.1074 - mean_squared_error: 189.7237 - val_loss: 141.7556 - val_mean_squared_error: 155.5827\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 176.9752 - mean_squared_error: 188.5796 - val_loss: 140.4636 - val_mean_squared_error: 154.3087\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 188.0731 - mean_squared_error: 187.6447 - val_loss: 139.7032 - val_mean_squared_error: 153.8024\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 185.4746 - mean_squared_error: 186.1161 - val_loss: 138.6869 - val_mean_squared_error: 152.7720\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 174.5676 - mean_squared_error: 184.8949 - val_loss: 137.5936 - val_mean_squared_error: 151.6150\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 183.6531 - mean_squared_error: 183.3344 - val_loss: 136.9423 - val_mean_squared_error: 151.1020\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 184.0569 - mean_squared_error: 182.8374 - val_loss: 136.1635 - val_mean_squared_error: 150.3810\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 181.0533 - mean_squared_error: 181.7828 - val_loss: 134.9986 - val_mean_squared_error: 149.1642\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 181.3005 - mean_squared_error: 180.0693 - val_loss: 133.6139 - val_mean_squared_error: 147.5672\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 180.0857 - mean_squared_error: 178.7657 - val_loss: 132.6214 - val_mean_squared_error: 146.5435\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 177.0977 - mean_squared_error: 177.6786 - val_loss: 131.6767 - val_mean_squared_error: 145.5343\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 177.7427 - mean_squared_error: 176.6250 - val_loss: 130.4418 - val_mean_squared_error: 144.2852\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 175.8930 - mean_squared_error: 175.4836 - val_loss: 129.5184 - val_mean_squared_error: 143.3424\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 175.1735 - mean_squared_error: 174.5272 - val_loss: 128.3101 - val_mean_squared_error: 142.1506\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 171.4458 - mean_squared_error: 173.2383 - val_loss: 127.2773 - val_mean_squared_error: 141.1452\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 173.1653 - mean_squared_error: 172.1605 - val_loss: 126.1758 - val_mean_squared_error: 139.9958\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 171.0530 - mean_squared_error: 171.0910 - val_loss: 125.1177 - val_mean_squared_error: 138.9509\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 167.6780 - mean_squared_error: 170.0036 - val_loss: 124.1416 - val_mean_squared_error: 137.9514\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 169.6484 - mean_squared_error: 168.6682 - val_loss: 123.0060 - val_mean_squared_error: 136.9011\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 160.4952 - mean_squared_error: 167.6728 - val_loss: 122.2737 - val_mean_squared_error: 136.2221\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 168.0162 - mean_squared_error: 166.7185 - val_loss: 121.3987 - val_mean_squared_error: 135.3320\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 164.5059 - mean_squared_error: 165.6539 - val_loss: 120.5992 - val_mean_squared_error: 134.5206\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 4ms/step - loss: 165.5663 - mean_squared_error: 164.7299 - val_loss: 119.7766 - val_mean_squared_error: 133.7096\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 164.9452 - mean_squared_error: 163.8197 - val_loss: 119.0981 - val_mean_squared_error: 133.0021\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 164.1225 - mean_squared_error: 163.0661 - val_loss: 118.3977 - val_mean_squared_error: 132.3058\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 161.5527 - mean_squared_error: 162.1593 - val_loss: 117.7592 - val_mean_squared_error: 131.6865\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 161.7756 - mean_squared_error: 161.3178 - val_loss: 117.0300 - val_mean_squared_error: 130.9775\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 161.7072 - mean_squared_error: 160.5278 - val_loss: 116.4298 - val_mean_squared_error: 130.3545\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 159.7092 - mean_squared_error: 159.7573 - val_loss: 115.7665 - val_mean_squared_error: 129.6735\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 158.6751 - mean_squared_error: 158.9158 - val_loss: 115.0516 - val_mean_squared_error: 128.9137\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 159.2754 - mean_squared_error: 158.1471 - val_loss: 114.4669 - val_mean_squared_error: 128.3422\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 158.2907 - mean_squared_error: 157.4749 - val_loss: 113.9204 - val_mean_squared_error: 127.8111\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 157.1621 - mean_squared_error: 157.0885 - val_loss: 113.6835 - val_mean_squared_error: 127.6553\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 155.1123 - mean_squared_error: 155.9576 - val_loss: 112.7217 - val_mean_squared_error: 126.6067\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 156.0795 - mean_squared_error: 155.1348 - val_loss: 112.0859 - val_mean_squared_error: 125.9176\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 153.8845 - mean_squared_error: 154.9317 - val_loss: 111.5509 - val_mean_squared_error: 125.3615\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 154.3229 - mean_squared_error: 153.3536 - val_loss: 111.4598 - val_mean_squared_error: 125.4291\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 154.3369 - mean_squared_error: 153.1391 - val_loss: 111.0578 - val_mean_squared_error: 125.0449\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 5ms/step - loss: 150.9223 - mean_squared_error: 152.5406 - val_loss: 110.2950 - val_mean_squared_error: 124.2224\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f973aff43c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFu2k4J_spfi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ca3bee9e-871b-4ad0-c7fc-1edf524d730e"
      },
      "source": [
        "loss, mse = model.evaluate(train_ds)\n",
        "print(\"Mean Squared Error - Test Data\", mse)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 0s 18ms/step - loss: 220.7047 - mean_squared_error: 151.8126\n",
            "Mean Squared Error - Test Data 151.81259\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn-9jxabDofQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "9c45d93e-6352-46df-fb78-4b3d25cc331d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_features_2 (DenseFeatu multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             multiple                  14        \n",
            "=================================================================\n",
            "Total params: 14\n",
            "Trainable params: 14\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDhV7jxiDqTm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca4af117-ab04-4b09-9ad8-6fda3b266808"
      },
      "source": [
        "import math\n",
        "math.sqrt(mse)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.3212252455969"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXGDrwBRVe7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}